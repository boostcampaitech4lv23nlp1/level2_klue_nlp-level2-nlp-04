path:
  train_path: ../dataset/train/train.csv
  dev_path: None # 대화 : train, test 나눔 -> 
  test_path: ../dataset/train/test.csv
  predict_path: ../dataset/test/test_data.csv
  save_path: SaveModels/

data:
  shuffle: True
  train_ratio: 0.1  # train(train+dev) dev(test셋) test : 라벨링

model:
  model_name: monologg/koelectra-base-v3-discriminator
  class_id: 0 # __getattr__ () :

train:
  max_epoch: 1
  batch_size: 32
  lr: 1e-5
  loss: ce
  warm_up: 0
  use_freeze: False
  
utils:
  seed: 42 # 마음대로 하셔도 됩니다.
  early_stop_monitor: val_loss # early
  best_save_monitor: val_micro_f1 # best
  patience: 25
  top_k: 3 # best

k_fold:
  use_k_fold: False
  num_folds: 3
  num_split: 5
  
wandb:
  project: level02-nlp-04


# 개인적인 tip으론 yaml 파일명에 해당 설정을 통해 얻은 성능을 함께 기록해두면 나중에 앙상블할 모델을 찾거나 재현할 때 편합니다
# 앞으로 모델 구조를 여기 안에 적어놔야겠다....